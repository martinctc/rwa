---
title: "Introduction to Relative Weights Analysis with the rwa Package"
author: "Martin Chan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to Relative Weights Analysis with the rwa Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  error = FALSE,
  warning = FALSE,
  message = FALSE
)
```

```{r setup}
library(rwa)
library(dplyr)
library(ggplot2)
```

## Introduction

**Relative Weights Analysis (RWA)** is a powerful method for determining the relative importance of predictor variables in multiple regression models, particularly when dealing with multicollinearity. This vignette provides a comprehensive guide to using the `rwa` package, explaining the methodology, interpreting results, and exploring advanced features including bootstrap confidence intervals.

## Background and Methodology

### What is Relative Weights Analysis?

Relative Weights Analysis addresses a fundamental problem in multiple regression: when predictor variables are correlated with each other (multicollinearity), it becomes difficult to determine the true contribution of each variable to the outcome. Traditional regression coefficients can be misleading, unstable, or difficult to interpret in the presence of multicollinearity.

RWA decomposes the total variance predicted in a regression model (R²) into weights that accurately reflect the proportional contribution of the various predictor variables. The method implemented in this package is based on **Tonidandel and LeBreton (2015)**, with its original roots in **Johnson (2000)**.

### How RWA Works

The core insight of RWA is to create a set of orthogonal (uncorrelated) variables that are maximally related to the original predictors, then use these in a regression model. The process involves:

1. **Eigenvalue decomposition** of the predictor correlation matrix
2. **Transformation** of predictors into orthogonal components
3. **Regression** using the transformed predictors
4. **Decomposition** of R² into relative weights

This approach allows us to determine each variable's unique contribution to the explained variance, even when predictors are highly correlated.

### When to Use RWA

RWA is particularly useful when:

- **Multicollinearity** is present among predictors
- You need to **rank variables** by importance
- **Traditional regression coefficients** are unstable or difficult to interpret
- You want to understand **proportional contributions** to explained variance
- Conducting **key drivers analysis** in market research or business analytics

## Basic Usage

### Simple Example with mtcars

Let's start with a basic example using the built-in `mtcars` dataset to predict fuel efficiency (`mpg`):

```{r basic-example}
# Basic RWA
result_basic <- mtcars %>%
  rwa(outcome = "mpg",
      predictors = c("cyl", "disp", "hp", "gear"))

# View the results
result_basic$result
```

### Understanding the Output

The basic output includes several key components:

```{r output-explanation}
# Predictor variables used
result_basic$predictors

# Model R-squared
result_basic$rsquare

# Number of complete observations
result_basic$n

# Correlation matrices (for advanced users)
str(result_basic$RXX)  # Predictor correlation matrix
str(result_basic$RXY)  # Predictor-outcome correlations
```

### Interpreting the Results Table

The main results table contains:

- **Variables**: Names of predictor variables
- **Raw.RelWeight**: Raw relative weights (sum to R²)
- **Rescaled.RelWeight**: Rescaled weights as percentages (sum to 100%)
- **Sign**: Direction of relationship with outcome (+/-)

```{r interpret-results}
# The rescaled weights show relative importance
result_basic$result %>%
  arrange(desc(Rescaled.RelWeight))

# Raw weights sum to R-squared
sum(result_basic$result$Raw.RelWeight)
result_basic$rsquare

# Rescaled weights sum to 100%
sum(result_basic$result$Rescaled.RelWeight)
```

## Advanced Features

### Adding Signs to Weights

The `applysigns` parameter adds directional information to help interpret whether variables positively or negatively influence the outcome:

```{r signs-example}
result_signs <- mtcars %>%
  rwa(outcome = "mpg",
      predictors = c("cyl", "disp", "hp", "gear"),
      applysigns = TRUE)

result_signs$result
```

### Visualization

The package automatically generates a visualization of the relative importance:

```{r visualization, fig.width=8, fig.height=5}
# Generate and display plot
plot_result <- mtcars %>%
  rwa(outcome = "mpg",
      predictors = c("cyl", "disp", "hp", "gear", "wt"),
      plot = TRUE)

# Display plot
plot_rwa(plot_result)
```

## Bootstrap Confidence Intervals

The `rwa` package includes powerful bootstrap functionality for determining the statistical significance of relative weights. For detailed coverage of bootstrap methods, see the dedicated vignette:

```{r eval=FALSE}
vignette("bootstrap-confidence-intervals", package = "rwa")
```

### Quick Bootstrap Example

```{r bootstrap-example}
# Basic bootstrap analysis
bootstrap_result <- mtcars %>%
  rwa(outcome = "mpg",
      predictors = c("cyl", "disp", "hp"),
      bootstrap = TRUE,
      n_bootstrap = 500)  # Reduced for speed

# View significant predictors
bootstrap_result$result %>%
  filter(Raw.Significant == TRUE) %>%
  select(Variables, Rescaled.RelWeight, Raw.RelWeight.CI.Lower, Raw.RelWeight.CI.Upper)
```

For comprehensive coverage of bootstrap methods, advanced features, and best practices, consult the bootstrap vignette.

## Real-World Example: Diamond Price Analysis

Let's explore a more complex example using the `diamonds` dataset:

```{r diamonds-example}
# Analyze diamond price drivers
diamonds_subset <- diamonds %>%
  select(price, carat, depth, table, x, y, z) %>%
  sample_n(1000)  # Sample for faster computation

diamond_rwa <- diamonds_subset %>%
  rwa(outcome = "price",
      predictors = c("carat", "depth", "table", "x", "y", "z"),
      applysigns = TRUE)

diamond_rwa$result
```

For bootstrap analysis of this example with confidence intervals, see:
```{r eval=FALSE}
vignette("bootstrap-confidence-intervals", package = "rwa")
```

## Comparison with Traditional Regression

Let's compare RWA results with traditional multiple regression to highlight the differences:

```{r regression-comparison}
# Traditional regression
lm_model <- lm(mpg ~ cyl + disp + hp + gear, data = mtcars)
lm_summary <- summary(lm_model)

# Display regression summary
print(lm_summary)

# RWA results
rwa_model <- mtcars %>%
  rwa(outcome = "mpg", predictors = c("cyl", "disp", "hp", "gear"))

# Compare importance rankings
comparison <- data.frame(
  Variable = rwa_model$predictors,
  RWA_Rescaled = rwa_model$result$Rescaled.RelWeight,
  RWA_Rank = rank(-rwa_model$result$Rescaled.RelWeight)
)

print(comparison)
```

## Best Practices and Recommendations

### 1. Sample Size Considerations

```{r sample-size}
# Check your sample size
n_obs <- mtcars %>% 
  select(mpg, cyl, disp, hp, gear) %>% 
  na.omit() %>% 
  nrow()

cat("Sample size:", n_obs)
cat("\nRule of thumb: At least 5 observations per predictor")
```

### 2. Variable Selection

RWA works best with:
- **Continuous variables** (though categorical can be used with caution)
- **Theoretically meaningful predictors**  
- **Reasonable predictor-to-observation ratios**

### 3. Reporting Results

When reporting RWA results, include:
- **Sample size** and missing data handling
- **Raw and rescaled weights**
- **Model R-squared**

For bootstrap confidence intervals and advanced statistical considerations, see:
```{r eval=FALSE}
vignette("bootstrap-confidence-intervals", package = "rwa")
```
- **Raw and rescaled weights**
- **Confidence intervals** for key predictors
- **Model R-squared**

## Troubleshooting Common Issues

### Multicollinearity Warnings

If you encounter extreme multicollinearity:

```{r multicollinearity-check}
# Check correlation matrix
cor_matrix <- mtcars %>%
  select(cyl, disp, hp, gear) %>%
  cor()

# Look for high correlations (>0.9)
high_cor <- which(abs(cor_matrix) > 0.9 & cor_matrix != 1, arr.ind = TRUE)
if(nrow(high_cor) > 0) {
  cat("High correlations detected between variables")
}
```

### Missing Data

RWA handles missing data through listwise deletion:

```{r missing-data}
# Check for missing data patterns
missing_summary <- mtcars %>%
  select(mpg, cyl, disp, hp, gear) %>%
  summarise_all(~sum(is.na(.)))

print(missing_summary)
```

## References

This package and methodology are based on the following key references:

**Primary Sources:**

- **Johnson, J. W. (2000)**. A heuristic method for estimating the relative weight of predictor variables in multiple regression. *Multivariate Behavioral Research*, 35(1), 1-19. DOI: 10.1207/S15327906MBR3501_1

- **Tonidandel, S., & LeBreton, J. M. (2015)**. RWA Web: A free, comprehensive, web-based, and user-friendly tool for relative weight analyses. *Journal of Business and Psychology*, 30(2), 207-216. DOI: 10.1007/s10869-014-9351-z

**Additional Reading:**

- Azen, R., & Budescu, D. V. (2003). The dominance analysis approach for comparing predictors in multiple regression. *Psychological Methods*, 8(2), 129-148.

- Grömping, U. (2006). Relative importance for linear regression in R: The package relaimpo. *Journal of Statistical Software*, 17(1), 1-27.

- Johnson, J. W., & LeBreton, J. M. (2004). History and use of relative importance indices in organizational research. *Organizational Research Methods*, 7(3), 238-257.

For bootstrap methods and statistical significance testing, see the dedicated bootstrap vignette and its references.

For the latest methodological developments: https://relativeimportance.davidson.edu/

## Conclusion

The `rwa` package provides a user-friendly implementation of Relative Weights Analysis in R with seamless tidyverse integration. This introductory vignette covered the basic methodology and usage patterns.

For advanced features including bootstrap confidence intervals and statistical significance testing, see:
```{r eval=FALSE}
vignette("bootstrap-confidence-intervals", package = "rwa")
```

Whether you're conducting key drivers analysis in market research, exploring variable importance in predictive modeling, or addressing multicollinearity in academic research, RWA provides valuable insights that complement traditional regression approaches.
